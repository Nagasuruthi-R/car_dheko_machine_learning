{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(os.path.join('../raw_data/', '*.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand 'top' field\n",
    "def expand_top(top_list):\n",
    "    return [item['value'] for item in top_list]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand 'data' field\n",
    "def expand_data(data_list):\n",
    "    expanded_data = {}\n",
    "    for item in data_list:\n",
    "        heading = item['heading']\n",
    "        expanded_data[heading] = [feature['value'] for feature in item['list']]\n",
    "    return expanded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "\n",
    "    # Extract 'top' features\n",
    "    df['top_features'] = df['new_car_feature'].apply(lambda x: expand_top(x['top']))\n",
    "\n",
    "    # Extract 'data' features\n",
    "    data_features = df['new_car_feature'].apply(lambda x: expand_data(x['data']))\n",
    "\n",
    "    # Normalize 'data_features' and concatenate with 'top_features'\n",
    "    data_features_df = pd.json_normalize(data_features)\n",
    "\n",
    "    # Concatenate 'top_features' and 'data_features_df'\n",
    "    top_feature_df = pd.concat([df[['top_features']], data_features_df], axis=1)\n",
    "\n",
    "    return top_feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_spec_data_generation(df, new_car_detail_flag = False):\n",
    "    rows = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Extract the 'top' list from the row\n",
    "        if not new_car_detail_flag:\n",
    "            top_list = row['top']\n",
    "        \n",
    "            # Create a dictionary for the current row\n",
    "            columns_dict = {item['key']: item['value'] for item in top_list}\n",
    "            # Append the dictionary to the list of rows\n",
    "            rows.append(columns_dict)\n",
    "        else:\n",
    "            rows.append(row)\n",
    "        \n",
    "\n",
    "    car_overview = pd.DataFrame(rows)\n",
    "    return car_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_multiple_dfs(new_car_overview_df, new_car_feature_df, new_car_specs_df, new_car_detail_df):\n",
    "    car_overview =new_car_overview_df.reset_index(drop = True)\n",
    "    top_feature_df = new_car_feature_df.reset_index(drop = True)\n",
    "    car_specs = new_car_specs_df.reset_index(drop = True)\n",
    "    newcar_details = new_car_detail_df.reset_index(drop = True)\n",
    "\n",
    "    final_df_combined = pd.concat([car_overview, top_feature_df, car_specs, newcar_details], axis = 1)\n",
    "\n",
    "    return final_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_final_df(final_df_combined, rename_dict):\n",
    "\n",
    "    # drop duplicate columns with same values\n",
    "    final_df_combined = final_df_combined.loc[:, ~final_df_combined.columns.duplicated()]\n",
    "\n",
    "    unwanted_columns = ['Registration Year', 'transmission', 'Kms Driven', 'Engine Displacement', 'trendingText.imgUrl', 'trendingText.heading', 'trendingText.desc', 'priceFixedText', \n",
    "                    'owner', 'it', 'ft', 'Ownership', 'Year of Manufacture']\n",
    "    \n",
    "    cars_df = final_df_combined.drop(columns=unwanted_columns)\n",
    "\n",
    "    cars_df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "    return cars_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete mapping dictionary\n",
    "rename_dict = {\n",
    "    'Insurance Validity': 'Insurance_Validity_Period',\n",
    "    'Fuel Type': 'Fuel_Type',\n",
    "    'Seats': 'Number_of_Seats',\n",
    "    'RTO': 'Regional_Transport_Office',\n",
    "    'Transmission': 'Transmission_Type',\n",
    "    'top_features': 'Top_Features',\n",
    "    'Comfort & Convenience': 'Comfort_and_Convenience',\n",
    "    'Interior': 'Interior_Features',\n",
    "    'Exterior': 'Exterior_Features',\n",
    "    'Safety': 'Safety_Features',\n",
    "    'Entertainment & Communication': 'Entertainment_and_Communication',\n",
    "    'Mileage': 'Mileage_(km/l)',\n",
    "    'Engine': 'Engine_Capacity',\n",
    "    'Max Power': 'Maximum_Power',\n",
    "    'Torque': 'Torque',\n",
    "    'Wheel Size': 'Wheel_Size',\n",
    "    'bt': 'Battery_Type',\n",
    "    'km': 'Kilometers_Driven',\n",
    "    'ownerNo': 'Number_of_Owners',\n",
    "    'oem': 'Original_Equipment_Manufacturer',\n",
    "    'model': 'Car_Model',\n",
    "    'modelYear': 'Model_Year',\n",
    "    'centralVariantId': 'Central_Variant_ID',\n",
    "    'variantName': 'Variant_Name',\n",
    "    'price': 'Listed_Price',\n",
    "    'priceActual': 'Actual_Price',\n",
    "    'priceSaving': 'Price_Saving_Amount'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_structured_excel_data(file_paths):\n",
    "    for file in file_paths:\n",
    "        # get file name\n",
    "        base_name = os.path.basename(file)\n",
    "        file_name = os.path.splitext(base_name)[0].split('_')[0]\n",
    "        \n",
    "\n",
    "        df = pd.read_excel(file)\n",
    "\n",
    "        \n",
    "        # changing new_car_overview from Object to json format to structure the data\n",
    "        df['new_car_overview'] = df['new_car_overview'].apply(ast.literal_eval)\n",
    "        new_car_expanded = pd.json_normalize(df['new_car_overview'])\n",
    "        new_car_overview_df = car_spec_data_generation(new_car_expanded)\n",
    "\n",
    "        # changing new_car_feature from Object to json format to structure the data\n",
    "        df['new_car_feature'] = df['new_car_feature'].apply(ast.literal_eval)\n",
    "        #features_expanded = pd.json_normalize(df['new_car_feature'])\n",
    "        new_car_feature_df = normalize_data(df)\n",
    "\n",
    "        # changing new_car_specs from Object to json format to structure the data\n",
    "        df['new_car_specs'] = df['new_car_specs'].apply(ast.literal_eval)\n",
    "        specs_expanded = pd.json_normalize(df['new_car_specs'])\n",
    "        new_car_specs_df = car_spec_data_generation(specs_expanded)\n",
    "\n",
    "        # changing new_car_specs from Object to json format to structure the data\n",
    "        df['new_car_detail'] = df['new_car_detail'].apply(ast.literal_eval)\n",
    "        detail_expanded = pd.json_normalize(df['new_car_detail'])\n",
    "        new_car_detail_df = car_spec_data_generation(detail_expanded, new_car_detail_flag=True)\n",
    "\n",
    "        final_df_combined = combine_multiple_dfs(new_car_overview_df, new_car_feature_df, new_car_specs_df, new_car_detail_df)\n",
    "\n",
    "        car_specs = cleaned_final_df(final_df_combined, rename_dict)\n",
    "\n",
    "        car_specs.to_excel(f'../cleaned_data/{file_name}_cars_cleaned.xlsx', index= False)\n",
    "\n",
    "        print(f'Structured data created for {file_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structured data created for bangalore\n",
      "Structured data created for chennai\n",
      "Structured data created for delhi\n",
      "Structured data created for hyderabad\n",
      "Structured data created for jaipur\n",
      "Structured data created for kolkata\n"
     ]
    }
   ],
   "source": [
    "generate_structured_excel_data(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m file_city_mapping[file_name]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Clean and convert `Listed_Price`\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mListed_Price\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mListed_Price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m₹\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLakh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     27\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mListed_Price\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mListed_Price\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100000\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Clean and convert `Actual_Price`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Green Gen Tech\\Desktop\\CarDhekoProject\\car_dheko_machine_learning\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   6293\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   6294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   6295\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   6296\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   6297\u001b[0m ):\n\u001b[0;32m   6298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 6299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Green Gen Tech\\Desktop\\CarDhekoProject\\car_dheko_machine_learning\\venv\\Lib\\site-packages\\pandas\\core\\accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\Green Gen Tech\\Desktop\\CarDhekoProject\\car_dheko_machine_learning\\venv\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:191\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Users\\Green Gen Tech\\Desktop\\CarDhekoProject\\car_dheko_machine_learning\\venv\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:245\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    242\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the mapping of file names to city names\n",
    "file_city_mapping = {\n",
    "    'bangalore_cars_cleaned.xlsx': 'bangalore',\n",
    "    'chennai_cars_cleaned.xlsx': 'chennai',\n",
    "    'delhi_cars_cleaned.xlsx': 'delhi',\n",
    "    'hyderabad_cars_cleaned.xlsx': 'hyderabad',\n",
    "    'jaipur_cars_cleaned.xlsx': 'jaipur',\n",
    "    'kolkata_cars_cleaned.xlsx': 'kolkata'\n",
    "}\n",
    "\n",
    "# Get all Excel file paths\n",
    "file_paths = glob.glob(os.path.join('../cleaned_data/', '*.xlsx'))\n",
    "\n",
    "# Iterate through each file\n",
    "for file_path in file_paths:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    if file_name in file_city_mapping:\n",
    "        # Read the Excel file\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        # Add the new column with the city name from the mapping\n",
    "        df['city'] = file_city_mapping[file_name]\n",
    "        \n",
    "        # Clean and convert `Listed_Price`\n",
    "        df['Listed_Price'] = df['Listed_Price'].str.replace('₹', '', regex=False).str.replace(',', '', regex=False).str.replace('Crore', '', regex=False).str.replace('Lakh', '', regex=False).str.strip()\n",
    "        df['Listed_Price'] = df['Listed_Price'].astype(float) * 100000\n",
    "        \n",
    "        # Clean and convert `Actual_Price`\n",
    "        df['Actual_Price'] = df['Actual_Price'].str.replace('₹', '', regex=False).str.replace(',', '', regex=False).str.replace('Crore', '', regex=False).str.replace('Lakh', '', regex=False).str.strip()\n",
    "        df['Actual_Price'] = df['Actual_Price'].astype(float) * 100000\n",
    "        \n",
    "        # Define the function to calculate the difference\n",
    "        def calculate_difference(row):\n",
    "            if pd.notnull(row['Actual_Price']) and pd.notnull(row['Listed_Price']):\n",
    "                return row['Actual_Price'] - row['Listed_Price']\n",
    "            else:\n",
    "                return np.nan\n",
    "        \n",
    "        # Apply the function to calculate the difference\n",
    "        df['Difference'] = df.apply(calculate_difference, axis=1)\n",
    "        \n",
    "        # Calculate the mean difference\n",
    "        mean_diff = df['Difference'].mean()\n",
    "        \n",
    "        # Fill missing `Actual_Price` values with `Listed_Price` + mean_diff\n",
    "        df['Actual_Price'] = df['Actual_Price'].fillna(df['Listed_Price'] + mean_diff)\n",
    "        \n",
    "        # Drop the `Difference` and `Price_Saving_Amount` columns\n",
    "        df.drop(columns=['Difference', 'Price_Saving_Amount'], inplace=True)\n",
    "        \n",
    "        # Save the updated DataFrame back to the Excel file\n",
    "        df.to_excel(file_path, index=False)\n",
    "\n",
    "        # Optionally, print or display the DataFrame to verify\n",
    "        print(f\"Updated {file_name}:\")\n",
    "        print(df.head())  # Display the first few rows to confirm the update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Insurance_Validity_Period            0\n",
       "Fuel_Type                            0\n",
       "Number_of_Seats                      3\n",
       "Regional_Transport_Office          184\n",
       "Transmission_Type                    0\n",
       "Top_Features                         0\n",
       "Comfort_and_Convenience             16\n",
       "Interior_Features                   14\n",
       "Exterior_Features                   16\n",
       "Safety_Features                     16\n",
       "Entertainment_and_Communication    231\n",
       "Mileage_(km/l)                      47\n",
       "Engine_Capacity                      0\n",
       "Maximum_Power                       10\n",
       "Torque                              10\n",
       "Wheel_Size                         544\n",
       "Battery_Type                         1\n",
       "Kilometers_Driven                    0\n",
       "Number_of_Owners                     0\n",
       "Original_Equipment_Manufacturer      0\n",
       "Car_Model                            0\n",
       "Model_Year                           0\n",
       "Central_Variant_ID                   0\n",
       "Variant_Name                         0\n",
       "Listed_Price                         0\n",
       "Actual_Price                         0\n",
       "city                                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1381, 27)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
